# Gradient-Descend-for-Logistic-Regression
Gradient Descend for Logistic Regression
# Specs
![specs](specs/specs1.png)
![specs1](specs/specs2.png)
![specs1](specs/specs3.png)

# Results
# Cross Entropy Loss vs Iteration: Learning rate = 0.1, step size = 0.001
![result1](results/0.1-0.001.png)
# Cross Entropy Loss vs Iteration: Learning rate = 0.1, step size = 0.01
![result2](results/0.1-0.01.png)
# Cross Entropy Loss vs Iteration: Learning rate = 0.1, step size = 0.05
![result3](results/0.1-0.05.png)
# Cross Entropy Loss vs Iteration: Learning rate = 0.1, step size = 0.1
![result4](results/0.1-0.1.png)
# Cross Entropy Loss vs Iteration: Learning rate = 0.1, step size = 0.5
![result5](results/0.1-0.5.png)
# L2 norm vs Step size
![result7](results/L2_vs_step_size.png)
